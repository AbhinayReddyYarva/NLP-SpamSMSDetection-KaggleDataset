{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building ML Classifiers: Basic Random Forest & Gradient Boosting models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading & cleaning text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   body_len  punct%    0    1    2    3    4    5    6    7  ...   8094  8095  \\\n",
      "0       128     4.7  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   0.0   \n",
      "1        49     4.1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   0.0   \n",
      "2        62     3.2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   0.0   \n",
      "3        28     7.1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   0.0   \n",
      "4       135     4.4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   0.0   \n",
      "\n",
      "   8096  8097  8098  8099  8100  8101  8102  8103  \n",
      "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "4   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "\n",
      "[5 rows x 8106 columns]\n",
      "   body_len  punct%  0  1  2  3  4  5  6  7  ...   8094  8095  8096  8097  \\\n",
      "0       128     4.7  0  0  0  0  0  0  0  0  ...      0     0     0     0   \n",
      "1        49     4.1  0  0  0  0  0  0  0  0  ...      0     0     0     0   \n",
      "2        62     3.2  0  0  0  0  0  0  0  0  ...      0     0     0     0   \n",
      "3        28     7.1  0  0  0  0  0  0  0  0  ...      0     0     0     0   \n",
      "4       135     4.4  0  0  0  0  0  0  0  0  ...      0     0     0     0   \n",
      "\n",
      "   8098  8099  8100  8101  8102  8103  \n",
      "0     0     0     0     0     0     0  \n",
      "1     0     0     0     0     0     0  \n",
      "2     0     0     0     0     0     0  \n",
      "3     0     0     0     0     0     0  \n",
      "4     0     0     0     0     0     0  \n",
      "\n",
      "[5 rows x 8106 columns]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import string\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "ps = nltk.PorterStemmer()\n",
    "\n",
    "data = pd.read_csv(\"SMSSpamCollection.tsv\", sep='\\t')\n",
    "data.columns = ['label', 'body_text']\n",
    "\n",
    "def count_punct(text):\n",
    "    count = sum([1 for char in text if char in string.punctuation]) # Counting puntuations\n",
    "    return round(count/(len(text) - text.count(\" \")), 3)*100  # Percentage of punctuations\n",
    "\n",
    "data['body_len'] = data['body_text'].apply(lambda x: len(x) - x.count(\" \"))\n",
    "data['punct%'] = data['body_text'].apply(lambda x: count_punct(x))\n",
    "\n",
    "def clean_text(text):\n",
    "    text = \"\".join([word.lower() for word in text if word not in string.punctuation]) # removing puntuations and creating list\n",
    "    tokens = re.split('\\W+', text) # removing multiple special characters --> '\\W+' ('\\W' -> single special character)\n",
    "    #tokens = re.findall('\\w+', text)  # alternative to above statement (Split -> '\\W+'; findall -> '\\w+')\n",
    "    text = [ps.stem(word) for word in tokens if word not in stopwords]  # stemmig the words\n",
    "    return text\n",
    "\n",
    "# TF-IDF\n",
    "tfidf_vect = TfidfVectorizer(analyzer=clean_text)\n",
    "X_tfidf = tfidf_vect.fit_transform(data['body_text'])\n",
    "X_features = pd.concat([data['body_len'], data['punct%'], pd.DataFrame(X_tfidf.toarray())], axis=1)\n",
    "print(X_features.head())\n",
    "\n",
    "# CountVectorizer\n",
    "count_vect = CountVectorizer(analyzer=clean_text)\n",
    "X_count = count_vect.fit_transform(data['body_text'])\n",
    "X_count_feat = pd.concat([data['body_len'], data['punct%'], pd.DataFrame(X_count.toarray())], axis=1)\n",
    "print(X_count_feat.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring RandomForestClassifier Attributes & Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__abstractmethods__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_abc_cache', '_abc_negative_cache', '_abc_negative_cache_version', '_abc_registry', '_estimator_type', '_get_param_names', '_make_estimator', '_set_oob_score', '_validate_X_predict', '_validate_estimator', '_validate_y_class_weight', 'apply', 'decision_path', 'feature_importances_', 'fit', 'get_params', 'predict', 'predict_log_proba', 'predict_proba', 'score', 'set_params']\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(dir(RandomForestClassifier))\n",
    "print(RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploing RandomForestClassifier through Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97307002, 0.97127469, 0.96945193, 0.95956873, 0.96226415])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_kfold = RandomForestClassifier(n_jobs=-1)\n",
    "k_fold = KFold(n_splits=5)\n",
    "cross_val_score(rf_kfold, X_features, data['label'], cv=k_fold, scoring='accuracy', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring RandomForestClassifier through holdout set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_features, data['label'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=50, max_depth=20, n_jobs=-1)\n",
    "rf_model = rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.05372391412142566, 'body_len'),\n",
       " (0.043465328102913106, 7350),\n",
       " (0.03525865295091706, 3134),\n",
       " (0.033836731937353204, 1803),\n",
       " (0.027930153898490895, 5724),\n",
       " (0.027704111988416488, 4796),\n",
       " (0.022141794137644277, 7027),\n",
       " (0.021302953942960688, 2031),\n",
       " (0.016993465753887563, 6746),\n",
       " (0.01693419866569699, 5078)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(zip(rf_model.feature_importances_, X_train.columns), reverse=True)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf_model.predict(X_test)\n",
    "precision, recall, fscore, support = score(y_test, y_pred, pos_label='spam', average='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 1.0 / Recall: 0.592 / Accuracy: 0.936\n"
     ]
    }
   ],
   "source": [
    "print('Precision: {} / Recall: {} / Accuracy: {}'.format(round(precision, 3),\n",
    "                                                        round(recall, 3),\n",
    "                                                        round((y_pred==y_test).sum() / len(y_pred),3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_RF(n_est, depth):\n",
    "    rf1 = RandomForestClassifier(n_estimators=n_est, max_depth=depth, n_jobs=-1)\n",
    "    rf_model1 = rf.fit(X_train, y_train)\n",
    "    y_pred1 = rf_model.predict(X_test)\n",
    "    precision1, recall1, fscore1, support1 = score(y_test, y_pred1, pos_label='spam', average='binary')\n",
    "    print('Est: {} / Depth: {} ---- Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "        n_est, depth, round(precision1, 3), round(recall1, 3),\n",
    "        round((y_pred1==y_test).sum() / len(y_pred1), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Est: 10 / Depth: 10 ---- Precision: 1.0 / Recall: 0.58 / Accuracy: 0.934\n",
      "Est: 10 / Depth: 20 ---- Precision: 1.0 / Recall: 0.557 / Accuracy: 0.931\n",
      "Est: 10 / Depth: 30 ---- Precision: 1.0 / Recall: 0.557 / Accuracy: 0.931\n",
      "Est: 10 / Depth: None ---- Precision: 1.0 / Recall: 0.557 / Accuracy: 0.931\n",
      "Est: 50 / Depth: 10 ---- Precision: 1.0 / Recall: 0.534 / Accuracy: 0.927\n",
      "Est: 50 / Depth: 20 ---- Precision: 1.0 / Recall: 0.517 / Accuracy: 0.925\n",
      "Est: 50 / Depth: 30 ---- Precision: 1.0 / Recall: 0.54 / Accuracy: 0.928\n",
      "Est: 50 / Depth: None ---- Precision: 1.0 / Recall: 0.563 / Accuracy: 0.932\n",
      "Est: 100 / Depth: 10 ---- Precision: 1.0 / Recall: 0.58 / Accuracy: 0.934\n",
      "Est: 100 / Depth: 20 ---- Precision: 1.0 / Recall: 0.575 / Accuracy: 0.934\n",
      "Est: 100 / Depth: 30 ---- Precision: 1.0 / Recall: 0.58 / Accuracy: 0.934\n",
      "Est: 100 / Depth: None ---- Precision: 1.0 / Recall: 0.552 / Accuracy: 0.93\n"
     ]
    }
   ],
   "source": [
    "for n_est in [10, 50, 100]:\n",
    "    for depth in [10, 20, 30, None]:\n",
    "        train_RF(n_est, depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Random forest with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf2 = RandomForestClassifier()\n",
    "param = {'n_estimators': [10, 150, 300],\n",
    "        'max_depth': [30, 60, 90, None]}\n",
    "\n",
    "gs = GridSearchCV(rf2, param, cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abhi\\Anaconda3\\envs\\py35\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\Abhi\\Anaconda3\\envs\\py35\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\Abhi\\Anaconda3\\envs\\py35\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\Abhi\\Anaconda3\\envs\\py35\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\Abhi\\Anaconda3\\envs\\py35\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\Abhi\\Anaconda3\\envs\\py35\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\Abhi\\Anaconda3\\envs\\py35\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>44.529136</td>\n",
       "      <td>1.509081</td>\n",
       "      <td>0.974493</td>\n",
       "      <td>0.999281</td>\n",
       "      <td>90</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 90, 'n_estimators': 300}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.978475</td>\n",
       "      <td>0.999326</td>\n",
       "      <td>...</td>\n",
       "      <td>0.975741</td>\n",
       "      <td>0.999102</td>\n",
       "      <td>0.966757</td>\n",
       "      <td>0.999775</td>\n",
       "      <td>0.973944</td>\n",
       "      <td>0.998877</td>\n",
       "      <td>4.767877</td>\n",
       "      <td>0.307954</td>\n",
       "      <td>0.004168</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>43.938558</td>\n",
       "      <td>1.210974</td>\n",
       "      <td>0.974133</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>None</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 300}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.977578</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.976640</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.969452</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.972147</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.328994</td>\n",
       "      <td>0.543204</td>\n",
       "      <td>0.002984</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>23.955285</td>\n",
       "      <td>0.933581</td>\n",
       "      <td>0.973954</td>\n",
       "      <td>0.999012</td>\n",
       "      <td>90</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 90, 'n_estimators': 150}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.978475</td>\n",
       "      <td>0.999102</td>\n",
       "      <td>...</td>\n",
       "      <td>0.972147</td>\n",
       "      <td>0.998877</td>\n",
       "      <td>0.966757</td>\n",
       "      <td>0.999102</td>\n",
       "      <td>0.974843</td>\n",
       "      <td>0.999102</td>\n",
       "      <td>0.678141</td>\n",
       "      <td>0.143061</td>\n",
       "      <td>0.004223</td>\n",
       "      <td>0.000110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>25.886885</td>\n",
       "      <td>0.977440</td>\n",
       "      <td>0.973415</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>None</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 150}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.979372</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.975741</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.968553</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.969452</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.988231</td>\n",
       "      <td>0.157695</td>\n",
       "      <td>0.004014</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.542940</td>\n",
       "      <td>0.471497</td>\n",
       "      <td>0.973235</td>\n",
       "      <td>0.998294</td>\n",
       "      <td>90</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 90, 'n_estimators': 10}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.975785</td>\n",
       "      <td>0.998428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.979335</td>\n",
       "      <td>0.997755</td>\n",
       "      <td>0.971249</td>\n",
       "      <td>0.998204</td>\n",
       "      <td>0.965858</td>\n",
       "      <td>0.998428</td>\n",
       "      <td>0.460693</td>\n",
       "      <td>0.095420</td>\n",
       "      <td>0.004529</td>\n",
       "      <td>0.000304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "8       44.529136         1.509081         0.974493          0.999281   \n",
       "11      43.938558         1.210974         0.974133          1.000000   \n",
       "7       23.955285         0.933581         0.973954          0.999012   \n",
       "10      25.886885         0.977440         0.973415          1.000000   \n",
       "6        5.542940         0.471497         0.973235          0.998294   \n",
       "\n",
       "   param_max_depth param_n_estimators  \\\n",
       "8               90                300   \n",
       "11            None                300   \n",
       "7               90                150   \n",
       "10            None                150   \n",
       "6               90                 10   \n",
       "\n",
       "                                      params  rank_test_score  \\\n",
       "8     {'max_depth': 90, 'n_estimators': 300}                1   \n",
       "11  {'max_depth': None, 'n_estimators': 300}                2   \n",
       "7     {'max_depth': 90, 'n_estimators': 150}                3   \n",
       "10  {'max_depth': None, 'n_estimators': 150}                4   \n",
       "6      {'max_depth': 90, 'n_estimators': 10}                5   \n",
       "\n",
       "    split0_test_score  split0_train_score       ...         split2_test_score  \\\n",
       "8            0.978475            0.999326       ...                  0.975741   \n",
       "11           0.977578            1.000000       ...                  0.976640   \n",
       "7            0.978475            0.999102       ...                  0.972147   \n",
       "10           0.979372            1.000000       ...                  0.975741   \n",
       "6            0.975785            0.998428       ...                  0.979335   \n",
       "\n",
       "    split2_train_score  split3_test_score  split3_train_score  \\\n",
       "8             0.999102           0.966757            0.999775   \n",
       "11            1.000000           0.969452            1.000000   \n",
       "7             0.998877           0.966757            0.999102   \n",
       "10            1.000000           0.968553            1.000000   \n",
       "6             0.997755           0.971249            0.998204   \n",
       "\n",
       "    split4_test_score  split4_train_score  std_fit_time  std_score_time  \\\n",
       "8            0.973944            0.998877      4.767877        0.307954   \n",
       "11           0.972147            1.000000     10.328994        0.543204   \n",
       "7            0.974843            0.999102      0.678141        0.143061   \n",
       "10           0.969452            1.000000      0.988231        0.157695   \n",
       "6            0.965858            0.998428      0.460693        0.095420   \n",
       "\n",
       "    std_test_score  std_train_score  \n",
       "8         0.004168         0.000298  \n",
       "11        0.002984         0.000000  \n",
       "7         0.004223         0.000110  \n",
       "10        0.004014         0.000000  \n",
       "6         0.004529         0.000304  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_fit1 = gs.fit(X_features, data['label'])\n",
    "pd.DataFrame(gs_fit1.cv_results_).sort_values('mean_test_score', ascending=False)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abhi\\Anaconda3\\envs\\py35\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\Abhi\\Anaconda3\\envs\\py35\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\Abhi\\Anaconda3\\envs\\py35\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\Abhi\\Anaconda3\\envs\\py35\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\Abhi\\Anaconda3\\envs\\py35\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\Abhi\\Anaconda3\\envs\\py35\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\Abhi\\Anaconda3\\envs\\py35\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>28.621162</td>\n",
       "      <td>1.044288</td>\n",
       "      <td>0.973415</td>\n",
       "      <td>0.998698</td>\n",
       "      <td>90</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 90, 'n_estimators': 150}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.977578</td>\n",
       "      <td>0.998877</td>\n",
       "      <td>...</td>\n",
       "      <td>0.975741</td>\n",
       "      <td>0.998653</td>\n",
       "      <td>0.966757</td>\n",
       "      <td>0.999102</td>\n",
       "      <td>0.971249</td>\n",
       "      <td>0.998428</td>\n",
       "      <td>4.887849</td>\n",
       "      <td>0.319068</td>\n",
       "      <td>0.003929</td>\n",
       "      <td>0.000262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>50.391550</td>\n",
       "      <td>1.337137</td>\n",
       "      <td>0.973415</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>None</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 300}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.977578</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.973944</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967655</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.971249</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.912391</td>\n",
       "      <td>0.514937</td>\n",
       "      <td>0.003630</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>50.071497</td>\n",
       "      <td>1.361245</td>\n",
       "      <td>0.972157</td>\n",
       "      <td>0.998922</td>\n",
       "      <td>90</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 90, 'n_estimators': 300}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.976682</td>\n",
       "      <td>0.998652</td>\n",
       "      <td>...</td>\n",
       "      <td>0.973046</td>\n",
       "      <td>0.999102</td>\n",
       "      <td>0.966757</td>\n",
       "      <td>0.999102</td>\n",
       "      <td>0.971249</td>\n",
       "      <td>0.998653</td>\n",
       "      <td>7.316556</td>\n",
       "      <td>0.160921</td>\n",
       "      <td>0.003227</td>\n",
       "      <td>0.000220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>27.836672</td>\n",
       "      <td>1.030481</td>\n",
       "      <td>0.971978</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>None</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 150}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.977578</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.973944</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.969452</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.969452</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.792111</td>\n",
       "      <td>0.214806</td>\n",
       "      <td>0.003299</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23.637409</td>\n",
       "      <td>0.810223</td>\n",
       "      <td>0.971080</td>\n",
       "      <td>0.992770</td>\n",
       "      <td>60</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 60, 'n_estimators': 150}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.976682</td>\n",
       "      <td>0.992812</td>\n",
       "      <td>...</td>\n",
       "      <td>0.968553</td>\n",
       "      <td>0.993489</td>\n",
       "      <td>0.965858</td>\n",
       "      <td>0.993040</td>\n",
       "      <td>0.970350</td>\n",
       "      <td>0.992366</td>\n",
       "      <td>0.952002</td>\n",
       "      <td>0.191064</td>\n",
       "      <td>0.003842</td>\n",
       "      <td>0.000479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "7       28.621162         1.044288         0.973415          0.998698   \n",
       "11      50.391550         1.337137         0.973415          1.000000   \n",
       "8       50.071497         1.361245         0.972157          0.998922   \n",
       "10      27.836672         1.030481         0.971978          1.000000   \n",
       "4       23.637409         0.810223         0.971080          0.992770   \n",
       "\n",
       "   param_max_depth param_n_estimators  \\\n",
       "7               90                150   \n",
       "11            None                300   \n",
       "8               90                300   \n",
       "10            None                150   \n",
       "4               60                150   \n",
       "\n",
       "                                      params  rank_test_score  \\\n",
       "7     {'max_depth': 90, 'n_estimators': 150}                1   \n",
       "11  {'max_depth': None, 'n_estimators': 300}                1   \n",
       "8     {'max_depth': 90, 'n_estimators': 300}                3   \n",
       "10  {'max_depth': None, 'n_estimators': 150}                4   \n",
       "4     {'max_depth': 60, 'n_estimators': 150}                5   \n",
       "\n",
       "    split0_test_score  split0_train_score       ...         split2_test_score  \\\n",
       "7            0.977578            0.998877       ...                  0.975741   \n",
       "11           0.977578            1.000000       ...                  0.973944   \n",
       "8            0.976682            0.998652       ...                  0.973046   \n",
       "10           0.977578            1.000000       ...                  0.973944   \n",
       "4            0.976682            0.992812       ...                  0.968553   \n",
       "\n",
       "    split2_train_score  split3_test_score  split3_train_score  \\\n",
       "7             0.998653           0.966757            0.999102   \n",
       "11            1.000000           0.967655            1.000000   \n",
       "8             0.999102           0.966757            0.999102   \n",
       "10            1.000000           0.969452            1.000000   \n",
       "4             0.993489           0.965858            0.993040   \n",
       "\n",
       "    split4_test_score  split4_train_score  std_fit_time  std_score_time  \\\n",
       "7            0.971249            0.998428      4.887849        0.319068   \n",
       "11           0.971249            1.000000      6.912391        0.514937   \n",
       "8            0.971249            0.998653      7.316556        0.160921   \n",
       "10           0.969452            1.000000      0.792111        0.214806   \n",
       "4            0.970350            0.992366      0.952002        0.191064   \n",
       "\n",
       "    std_test_score  std_train_score  \n",
       "7         0.003929         0.000262  \n",
       "11        0.003630         0.000000  \n",
       "8         0.003227         0.000220  \n",
       "10        0.003299         0.000000  \n",
       "4         0.003842         0.000479  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_fit2 = gs.fit(X_count_feat, data['label'])\n",
    "pd.DataFrame(gs_fit2.cv_results_).sort_values('mean_test_score', ascending=False)[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring GradientBoostingClassifier Attributes & Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_SUPPORTED_LOSS', '__abstractmethods__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_abc_cache', '_abc_negative_cache', '_abc_negative_cache_version', '_abc_registry', '_check_initialized', '_check_params', '_clear_state', '_decision_function', '_estimator_type', '_fit_stage', '_fit_stages', '_get_param_names', '_init_decision_function', '_init_state', '_is_initialized', '_make_estimator', '_resize_state', '_staged_decision_function', '_validate_estimator', '_validate_y', 'apply', 'decision_function', 'feature_importances_', 'fit', 'get_params', 'n_features', 'predict', 'predict_log_proba', 'predict_proba', 'score', 'set_params', 'staged_decision_function', 'staged_predict', 'staged_predict_proba']\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              n_iter_no_change=None, presort='auto', random_state=None,\n",
      "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
      "              verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(dir(GradientBoostingClassifier))\n",
    "print(GradientBoostingClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Grid Search for Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_GB(est, max_depth, lr):\n",
    "    gb = GradientBoostingClassifier(n_estimators=est, max_depth=max_depth, learning_rate=lr)\n",
    "    gb_model = gb.fit(X_train, y_train)\n",
    "    y_pred2 = gb_model.predict(X_test)\n",
    "    precision2, recall2, fscore2, train_support2 = score(y_test, y_pred2, pos_label='spam', average='binary')\n",
    "    print('Est: {} / Depth: {} / LR: {} ---- Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "        est, max_depth, lr, round(precision2, 3), round(recall2, 3), \n",
    "        round((y_pred2==y_test).sum()/len(y_pred2), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abhi\\Anaconda3\\envs\\py35\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Est: 50 / Depth: 3 / LR: 0.01 ---- Precision: 0.0 / Recall: 0.0 / Accuracy: 0.844\n",
      "Est: 50 / Depth: 3 / LR: 0.1 ---- Precision: 0.947 / Recall: 0.713 / Accuracy: 0.949\n",
      "Est: 50 / Depth: 3 / LR: 1 ---- Precision: 0.908 / Recall: 0.799 / Accuracy: 0.956\n",
      "Est: 50 / Depth: 7 / LR: 0.01 ---- Precision: 1.0 / Recall: 0.006 / Accuracy: 0.845\n",
      "Est: 50 / Depth: 7 / LR: 0.1 ---- Precision: 0.929 / Recall: 0.833 / Accuracy: 0.964\n",
      "Est: 50 / Depth: 7 / LR: 1 ---- Precision: 0.869 / Recall: 0.799 / Accuracy: 0.95\n",
      "Est: 50 / Depth: 11 / LR: 0.01 ---- Precision: 1.0 / Recall: 0.011 / Accuracy: 0.846\n",
      "Est: 50 / Depth: 11 / LR: 0.1 ---- Precision: 0.929 / Recall: 0.833 / Accuracy: 0.964\n",
      "Est: 50 / Depth: 11 / LR: 1 ---- Precision: 0.886 / Recall: 0.845 / Accuracy: 0.959\n",
      "Est: 50 / Depth: 15 / LR: 0.01 ---- Precision: 1.0 / Recall: 0.017 / Accuracy: 0.846\n",
      "Est: 50 / Depth: 15 / LR: 0.1 ---- Precision: 0.925 / Recall: 0.845 / Accuracy: 0.965\n",
      "Est: 50 / Depth: 15 / LR: 1 ---- Precision: 0.881 / Recall: 0.81 / Accuracy: 0.953\n",
      "Est: 100 / Depth: 3 / LR: 0.01 ---- Precision: 0.946 / Recall: 0.5 / Accuracy: 0.917\n",
      "Est: 100 / Depth: 3 / LR: 0.1 ---- Precision: 0.959 / Recall: 0.81 / Accuracy: 0.965\n",
      "Est: 100 / Depth: 3 / LR: 1 ---- Precision: 0.906 / Recall: 0.828 / Accuracy: 0.96\n",
      "Est: 100 / Depth: 7 / LR: 0.01 ---- Precision: 0.957 / Recall: 0.632 / Accuracy: 0.938\n",
      "Est: 100 / Depth: 7 / LR: 0.1 ---- Precision: 0.929 / Recall: 0.833 / Accuracy: 0.964\n",
      "Est: 100 / Depth: 7 / LR: 1 ---- Precision: 0.865 / Recall: 0.81 / Accuracy: 0.951\n",
      "Est: 100 / Depth: 11 / LR: 0.01 ---- Precision: 0.94 / Recall: 0.718 / Accuracy: 0.949\n",
      "Est: 100 / Depth: 11 / LR: 0.1 ---- Precision: 0.925 / Recall: 0.856 / Accuracy: 0.967\n",
      "Est: 100 / Depth: 11 / LR: 1 ---- Precision: 0.894 / Recall: 0.828 / Accuracy: 0.958\n",
      "Est: 100 / Depth: 15 / LR: 0.01 ---- Precision: 0.93 / Recall: 0.764 / Accuracy: 0.954\n",
      "Est: 100 / Depth: 15 / LR: 0.1 ---- Precision: 0.925 / Recall: 0.845 / Accuracy: 0.965\n",
      "Est: 100 / Depth: 15 / LR: 1 ---- Precision: 0.899 / Recall: 0.822 / Accuracy: 0.958\n",
      "Est: 150 / Depth: 3 / LR: 0.01 ---- Precision: 0.929 / Recall: 0.529 / Accuracy: 0.92\n",
      "Est: 150 / Depth: 3 / LR: 0.1 ---- Precision: 0.966 / Recall: 0.822 / Accuracy: 0.968\n",
      "Est: 150 / Depth: 3 / LR: 1 ---- Precision: 0.941 / Recall: 0.822 / Accuracy: 0.964\n",
      "Est: 150 / Depth: 7 / LR: 0.01 ---- Precision: 0.931 / Recall: 0.695 / Accuracy: 0.944\n",
      "Est: 150 / Depth: 7 / LR: 0.1 ---- Precision: 0.942 / Recall: 0.839 / Accuracy: 0.967\n",
      "Est: 150 / Depth: 7 / LR: 1 ---- Precision: 0.865 / Recall: 0.81 / Accuracy: 0.951\n",
      "Est: 150 / Depth: 11 / LR: 0.01 ---- Precision: 0.937 / Recall: 0.764 / Accuracy: 0.955\n",
      "Est: 150 / Depth: 11 / LR: 0.1 ---- Precision: 0.924 / Recall: 0.839 / Accuracy: 0.964\n",
      "Est: 150 / Depth: 11 / LR: 1 ---- Precision: 0.885 / Recall: 0.839 / Accuracy: 0.958\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-023fa082af35>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mmax_depth\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m11\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m15\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m             \u001b[0mtrain_GB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_est\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-31-8e012cc97c8b>\u001b[0m in \u001b[0;36mtrain_GB\u001b[1;34m(est, max_depth, lr)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtrain_GB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mgb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGradientBoostingClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mgb_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0my_pred2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgb_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprecision2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecall2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscore2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_support2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'spam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py35\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m   1463\u001b[0m         n_stages = self._fit_stages(X, y, y_pred, sample_weight, self._rng,\n\u001b[0;32m   1464\u001b[0m                                     \u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1465\u001b[1;33m                                     begin_at_stage, monitor, X_idx_sorted)\n\u001b[0m\u001b[0;32m   1466\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1467\u001b[0m         \u001b[1;31m# change shape of arrays after fit (early-stopping or additional ests)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py35\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[1;34m(self, X, y, y_pred, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1527\u001b[0m             y_pred = self._fit_stage(i, X, y, y_pred, sample_weight,\n\u001b[0;32m   1528\u001b[0m                                      \u001b[0msample_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1529\u001b[1;33m                                      X_csc, X_csr)\n\u001b[0m\u001b[0;32m   1530\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1531\u001b[0m             \u001b[1;31m# track deviance (= loss)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py35\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[1;34m(self, i, X, y, y_pred, sample_weight, sample_mask, random_state, X_idx_sorted, X_csc, X_csr)\u001b[0m\n\u001b[0;32m   1192\u001b[0m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1193\u001b[0m             tree.fit(X, residual, sample_weight=sample_weight,\n\u001b[1;32m-> 1194\u001b[1;33m                      check_input=False, X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m   1195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m             \u001b[1;31m# update tree leaves\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py35\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1137\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1138\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1139\u001b[1;33m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m   1140\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py35\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    363\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 365\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    366\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    367\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for n_est in [50, 100, 150]:\n",
    "    for max_depth in [3, 7, 11, 15]:\n",
    "        for lr in [0.01, 0.1, 1]:\n",
    "            train_GB(n_est, max_depth, lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Gradient Boosting with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "gb2 = GradientBoostingClassifier()\n",
    "param = {\n",
    "    'n_estimators': [100, 150], \n",
    "    'max_depth': [7, 11, 15],\n",
    "    'learning_rate': [0.1]\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(gb2, param, cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_fit = clf.fit(X_features, data['label'])\n",
    "pd.DataFrame(cv_fit.cv_results_).sort_values('mean_test_score', ascending=False)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_fit = clf.fit(X_count_feat, data['label'])\n",
    "pd.DataFrame(cv_fit.cv_results_).sort_values('mean_test_score', ascending=False)[0:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
